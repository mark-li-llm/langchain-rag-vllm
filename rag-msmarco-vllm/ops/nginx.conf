# Nginx configuration for RAG MS MARCO deployment
# Provides load balancing between two vLLM servers and proxies RAG API

# Main configuration
worker_processes auto;
worker_rlimit_nofile 65535;

events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    # Basic settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 32m;

    # MIME types
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format for structured logs
    log_format json_combined escape=json
        '{'
        '"timestamp":"$time_iso8601",'
        '"remote_addr":"$remote_addr",'
        '"remote_user":"$remote_user",'
        '"request":"$request",'
        '"status":$status,'
        '"bytes_sent":$bytes_sent,'
        '"request_time":$request_time,'
        '"upstream_response_time":"$upstream_response_time",'
        '"upstream_status":"$upstream_status",'
        '"http_referer":"$http_referer",'
        '"http_user_agent":"$http_user_agent",'
        '"http_x_forwarded_for":"$http_x_forwarded_for",'
        '"upstream_addr":"$upstream_addr"'
        '}';

    # Access and error logs
    access_log /var/log/nginx/access.log json_combined;
    error_log /var/log/nginx/error.log warn;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    limit_req_zone $binary_remote_addr zone=llm_limit:10m rate=30r/m;

    # Upstream configuration for vLLM servers
    upstream vllm_pool {
        # Load balancing method
        least_conn;

        # vLLM Server A
        server vllm-a:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # vLLM Server B  
        server vllm-b:8000 max_fails=3 fail_timeout=30s weight=1;

        # Connection pooling
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }

    # Upstream for RAG API
    upstream rag_api {
        server rag_api:8000 max_fails=2 fail_timeout=10s weight=1;
        keepalive 16;
    }

    # Main server configuration
    server {
        listen 8080;
        server_name _;

        # Security headers
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;

        # Health check endpoint (nginx itself)
        location /nginx/health {
            access_log off;
            return 200 "nginx healthy\n";
            add_header Content-Type text/plain;
        }

        # RAG API endpoints
        location /v1/ {
            # Rate limiting
            limit_req zone=api_limit burst=20 nodelay;

            # Proxy to RAG API
            proxy_pass http://rag_api/v1/;
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";
            
            # Pass through Authorization header
            proxy_pass_header Authorization;
            
            # Timeouts
            proxy_connect_timeout 10s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # Buffering for non-streaming endpoints
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            
            # Handle errors
            proxy_next_upstream error timeout http_502 http_503;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 30s;
        }

        # Special handling for streaming query endpoint
        location /v1/query {
            # Rate limiting with higher burst for streaming
            limit_req zone=api_limit burst=10 nodelay;

            # Proxy to RAG API with streaming support
            proxy_pass http://rag_api/v1/query;
            
            # Headers for streaming
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";
            proxy_pass_header Authorization;
            
            # Streaming configuration
            proxy_http_version 1.1;
            proxy_buffering off;
            proxy_cache off;
            chunked_transfer_encoding on;
            
            # Timeouts for streaming (longer read timeout)
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;
            proxy_read_timeout 300s;
            
            # Error handling
            proxy_next_upstream error timeout http_502 http_503;
            proxy_next_upstream_tries 2;
        }

        # LLM endpoints (internal routing to vLLM pool)
        # This is used by the RAG API to communicate with vLLM servers
        location /llm/ {
            # Rate limiting for LLM requests
            limit_req zone=llm_limit burst=10 nodelay;

            # Internal access only (can be called by RAG API container)
            # In production, you might want to restrict this further
            allow 172.16.0.0/12;  # Docker network range
            allow 10.0.0.0/8;     # Private network range
            allow 192.168.0.0/16; # Private network range
            deny all;

            # Rewrite URL to remove /llm prefix
            rewrite ^/llm/(.*)$ /$1 break;
            
            # Proxy to vLLM pool
            proxy_pass http://vllm_pool;
            
            # Headers for vLLM
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_pass_header Authorization;
            
            # Streaming support for LLM responses
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_buffering off;
            proxy_cache off;
            chunked_transfer_encoding on;
            
            # Timeouts for LLM requests (can be slow)
            proxy_connect_timeout 30s;
            proxy_send_timeout 600s;
            proxy_read_timeout 600s;
            
            # Failover between vLLM servers
            proxy_next_upstream error timeout http_502 http_503;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 60s;
        }

        # Status and monitoring endpoints
        location /status {
            access_log off;
            stub_status on;
            
            # Restrict access to monitoring
            allow 172.16.0.0/12;
            allow 10.0.0.0/8;
            allow 192.168.0.0/16;
            allow 127.0.0.1;
            deny all;
        }

        # Block common attack patterns
        location ~ /\.ht {
            deny all;
        }

        location ~ /\. {
            deny all;
        }

        # Default location (return 404 for undefined paths)
        location / {
            return 404 "Not Found";
            add_header Content-Type text/plain;
        }
    }
}